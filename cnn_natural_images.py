# -*- coding: utf-8 -*-
"""CNN_natural_images.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mMXXQltAClNyNd9iy79xBg8tMkzJYz65
"""

import tensorflow as tf



!nvidia-smi

dataset = ('/content/drive/MyDrive/Colab Notebooks/ANN/natural_images')

import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten
from tensorflow.keras import models,layers
from keras.layers.core import Dense
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

len(dataset)

split_1 = int(0.8 * len(dataset))
split_2 = int(0.9 * len(dataset))
train_file = dataset[:split_1]
dev_file = dataset[split_1:split_2]
test_file = dataset[split_2:]

image_size = 256
batch_size = 32

model = tf.keras.preprocessing.image_dataset_from_directory("/content/drive/MyDrive/Colab Notebooks/ANN/natural_images",shuffle = True,
                                                            image_size =(image_size,image_size),
                                                            batch_size=batch_size)

class_names = model.class_names
class_names

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
label = le.fit_transform(class_names)

print(label)



for image_batch,label_batch in model.take(1):
  print(image_batch.shape)
  print(label_batch.numpy())

plt.figure(figsize=(5,5))

for image_batch,label_batch in model.take(1):
  for i in range(12):
    ax = plt.subplot(3,4,i+1)
    plt.imshow(image_batch[i].numpy().astype("int"))
    plt.axis("off")

len(model)

train_size = 0.8
len(model)*train_size

train_ds = model.take(172)
len(train_ds)

test_ds = model.skip(172)
len(test_ds)

val_size = 0.1
len(model)*val_size

val_ds = test_ds.take(21)
len(val_ds)

test_ds = test_ds.skip(21)
len(test_ds)

print(len(train_ds)),print(len(test_ds)),print(len(val_ds))

train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)
test_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)
val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)

from keras.api._v2.keras import preprocessing
resize_and_rescale = tf.keras.Sequential([
            layers.experimental.preprocessing.Rescaling(1.0/255)])

data_augmentation = tf.keras.Sequential([
    layers.experimental.preprocessing.RandomFlip("horizontal_and_vertical"),
    layers.experimental.preprocessing.RandomRotation(0.2)
])

input_shape=(len(model),256,256,3)
n_classes = 6

n_model = models.Sequential([
    resize_and_rescale,
    data_augmentation,

    layers.Conv2D(32,(3,3),activation = 'relu',input_shape=input_shape),
    layers.MaxPooling2D((2,2)),

    layers.Conv2D(64,kernel_size=(3,3),activation='relu'),
    layers.MaxPooling2D((2,2)),

    layers.Conv2D(64,kernel_size=(3,3),activation='relu'),
    layers.MaxPooling2D((2,2)),

    layers.Conv2D(64,kernel_size = (3,3),activation='relu'),
    layers.MaxPooling2D((2,2)),

    layers.Conv2D(64,kernel_size = (3,3),activation='relu'),
    layers.MaxPooling2D((2,2)),

    layers.Conv2D(64,kernel_size = (3,3),activation='relu'),
    layers.MaxPooling2D((2,2)),

    layers.Flatten(),
    layers.Dense(64,activation='relu'),
    layers.Dense(n_classes,activation='softmax'),


])

n_model.build(input_shape=input_shape)

n_model.summary()

n_model.compile(
    optimizer = 'adam',
    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
    metrics=['accuracy']
)

history = n_model.fit(
    train_ds,
    epochs = 10,
    batch_size = 32,
    verbose = 1,
    validation_data = val_ds
)

scores = n_model.evaluate(test_ds)

scores

history

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']



epochs = 10

plt.figure(figsize=(8,8))
plt.subplot(1,2,1)
plt.plot(range(epochs),acc,label='training accuracy')
plt.plot(range(epochs),val_acc,label='validation accuracy')
plt.legend(loc='best')
plt.title('training and validation accuracy')

import numpy as np
for images_batch,labels_batch in test_ds.take(1):
  first_image = images_batch[0].numpy().astype('uint8')
  first_label = labels_batch[0].numpy()

  print("first image to predict")
  plt.imshow(first_image)
  print("actual label:",label[first_label])

  batch_prediction = n_model.predict(images_batch)
  print("predicted label:",label[np.argmax(batch_prediction[0])])

